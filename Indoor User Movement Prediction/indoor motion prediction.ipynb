{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('MovementAAL/dataset/MovementAAL_target.csv')\n",
    "targets = targets.values[:,1]\n",
    "targets = targets.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'MovementAAL/dataset/MovementAAL_RSS_'\n",
    "sequences = list()\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(1,315):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    #print(file_path)\n",
    "    if targets[i-1] == 1:\n",
    "        t = 1\n",
    "    else:\n",
    "        t = 0\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "    values = df.values\n",
    "    values = scale.fit_transform(values)\n",
    "    #m,n = np.shape(values)\n",
    "    #value = values.reshape([1,n*m]).tolist()\n",
    "    for j in values:\n",
    "        data.append(j)\n",
    "        labels.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = keras.utils.to_categorical(labels,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "(training_inputs,\n",
    " testing_inputs,\n",
    " training_classes,\n",
    " testing_classes) = train_test_split(data, labels, train_size=0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9897 samples, validate on 3300 samples\n",
      "Epoch 1/100\n",
      "9897/9897 [==============================] - 18s 2ms/step - loss: 0.6907 - acc: 0.5701 - val_loss: 0.6883 - val_acc: 0.5727\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.57273, saving model to mpl_model.pkl\n",
      "Epoch 2/100\n",
      "9897/9897 [==============================] - 7s 740us/step - loss: 0.6857 - acc: 0.5593 - val_loss: 0.6844 - val_acc: 0.5727\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.57273\n",
      "Epoch 3/100\n",
      "9897/9897 [==============================] - 7s 737us/step - loss: 0.6791 - acc: 0.5708 - val_loss: 0.6738 - val_acc: 0.5727\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.57273\n",
      "Epoch 4/100\n",
      "9897/9897 [==============================] - 7s 747us/step - loss: 0.6706 - acc: 0.5916 - val_loss: 0.6601 - val_acc: 0.6182\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.57273 to 0.61818, saving model to mpl_model.pkl\n",
      "Epoch 5/100\n",
      "9897/9897 [==============================] - 8s 778us/step - loss: 0.6622 - acc: 0.6076 - val_loss: 0.6560 - val_acc: 0.6221\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.61818 to 0.62212, saving model to mpl_model.pkl\n",
      "Epoch 6/100\n",
      "9897/9897 [==============================] - 8s 771us/step - loss: 0.6634 - acc: 0.6039 - val_loss: 0.6521 - val_acc: 0.6174\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.62212\n",
      "Epoch 7/100\n",
      "9897/9897 [==============================] - 8s 773us/step - loss: 0.6590 - acc: 0.6144 - val_loss: 0.6580 - val_acc: 0.6080\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.62212\n",
      "Epoch 8/100\n",
      "9897/9897 [==============================] - 8s 822us/step - loss: 0.6553 - acc: 0.6199 - val_loss: 0.6504 - val_acc: 0.6374\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.62212 to 0.63742, saving model to mpl_model.pkl\n",
      "Epoch 9/100\n",
      "9897/9897 [==============================] - 8s 804us/step - loss: 0.6561 - acc: 0.6100 - val_loss: 0.6502 - val_acc: 0.6223\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.63742\n",
      "Epoch 10/100\n",
      "9897/9897 [==============================] - 8s 786us/step - loss: 0.6564 - acc: 0.6132 - val_loss: 0.6484 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.63742 to 0.64288, saving model to mpl_model.pkl\n",
      "Epoch 11/100\n",
      "9897/9897 [==============================] - 8s 783us/step - loss: 0.6513 - acc: 0.6243 - val_loss: 0.6452 - val_acc: 0.6405\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.64288\n",
      "Epoch 12/100\n",
      "9897/9897 [==============================] - 8s 800us/step - loss: 0.6499 - acc: 0.6167 - val_loss: 0.6450 - val_acc: 0.6365\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.64288\n",
      "Epoch 13/100\n",
      "9897/9897 [==============================] - 8s 804us/step - loss: 0.6494 - acc: 0.6264 - val_loss: 0.6437 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.64288\n",
      "Epoch 14/100\n",
      "9897/9897 [==============================] - 9s 859us/step - loss: 0.6508 - acc: 0.6249 - val_loss: 0.6454 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.64288\n",
      "Epoch 15/100\n",
      "9897/9897 [==============================] - 8s 800us/step - loss: 0.6510 - acc: 0.6240 - val_loss: 0.6428 - val_acc: 0.6453\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.64288 to 0.64530, saving model to mpl_model.pkl\n",
      "Epoch 16/100\n",
      "9897/9897 [==============================] - 8s 806us/step - loss: 0.6493 - acc: 0.6247 - val_loss: 0.6505 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.64530\n",
      "Epoch 17/100\n",
      "9897/9897 [==============================] - 8s 835us/step - loss: 0.6519 - acc: 0.6231 - val_loss: 0.6494 - val_acc: 0.6406\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.64530\n",
      "Epoch 18/100\n",
      "9897/9897 [==============================] - 8s 797us/step - loss: 0.6498 - acc: 0.6280 - val_loss: 0.6434 - val_acc: 0.6382\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.64530\n",
      "Epoch 19/100\n",
      "9897/9897 [==============================] - 8s 810us/step - loss: 0.6476 - acc: 0.6222 - val_loss: 0.6424 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.64530\n",
      "Epoch 20/100\n",
      "9897/9897 [==============================] - 8s 814us/step - loss: 0.6499 - acc: 0.6223 - val_loss: 0.6421 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.64530\n",
      "Epoch 21/100\n",
      "9897/9897 [==============================] - 8s 857us/step - loss: 0.6523 - acc: 0.6258 - val_loss: 0.6445 - val_acc: 0.6430\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.64530\n",
      "Epoch 22/100\n",
      "9897/9897 [==============================] - 9s 899us/step - loss: 0.6499 - acc: 0.6245 - val_loss: 0.6449 - val_acc: 0.6391\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.64530\n",
      "Epoch 23/100\n",
      "9897/9897 [==============================] - 9s 894us/step - loss: 0.6482 - acc: 0.6329 - val_loss: 0.6420 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.64530 to 0.64576, saving model to mpl_model.pkl\n",
      "Epoch 24/100\n",
      "9897/9897 [==============================] - 9s 883us/step - loss: 0.6486 - acc: 0.6250 - val_loss: 0.6468 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.64576\n",
      "Epoch 25/100\n",
      "9897/9897 [==============================] - 9s 891us/step - loss: 0.6488 - acc: 0.6233 - val_loss: 0.6424 - val_acc: 0.6445\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.64576\n",
      "Epoch 26/100\n",
      "9897/9897 [==============================] - 9s 882us/step - loss: 0.6490 - acc: 0.6271 - val_loss: 0.6427 - val_acc: 0.6432\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.64576\n",
      "Epoch 27/100\n",
      "9897/9897 [==============================] - 9s 880us/step - loss: 0.6511 - acc: 0.6246 - val_loss: 0.6457 - val_acc: 0.6318\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.64576\n",
      "Epoch 28/100\n",
      "9897/9897 [==============================] - 9s 899us/step - loss: 0.6464 - acc: 0.6271 - val_loss: 0.6478 - val_acc: 0.6342\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.64576\n",
      "Epoch 29/100\n",
      "9897/9897 [==============================] - 9s 932us/step - loss: 0.6440 - acc: 0.6277 - val_loss: 0.6394 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.64576\n",
      "Epoch 30/100\n",
      "9897/9897 [==============================] - 9s 935us/step - loss: 0.6450 - acc: 0.6344 - val_loss: 0.6430 - val_acc: 0.6433\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.64576\n",
      "Epoch 31/100\n",
      "9897/9897 [==============================] - 9s 891us/step - loss: 0.6476 - acc: 0.6240 - val_loss: 0.6420 - val_acc: 0.6459\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.64576 to 0.64591, saving model to mpl_model.pkl\n",
      "Epoch 32/100\n",
      "9897/9897 [==============================] - 9s 884us/step - loss: 0.6465 - acc: 0.6257 - val_loss: 0.6415 - val_acc: 0.6492\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.64591 to 0.64924, saving model to mpl_model.pkl\n",
      "Epoch 33/100\n",
      "9897/9897 [==============================] - 9s 886us/step - loss: 0.6423 - acc: 0.6227 - val_loss: 0.6424 - val_acc: 0.6480\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.64924\n",
      "Epoch 34/100\n",
      "9897/9897 [==============================] - 9s 883us/step - loss: 0.6420 - acc: 0.6301 - val_loss: 0.6397 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.64924 to 0.65091, saving model to mpl_model.pkl\n",
      "Epoch 35/100\n",
      "9897/9897 [==============================] - 9s 936us/step - loss: 0.6478 - acc: 0.6272 - val_loss: 0.6464 - val_acc: 0.6355\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.65091\n",
      "Epoch 36/100\n",
      "9897/9897 [==============================] - 9s 895us/step - loss: 0.6459 - acc: 0.6201 - val_loss: 0.6389 - val_acc: 0.6423\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.65091\n",
      "Epoch 37/100\n",
      "9897/9897 [==============================] - 9s 886us/step - loss: 0.6446 - acc: 0.6295 - val_loss: 0.6404 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.65091\n",
      "Epoch 38/100\n",
      "9897/9897 [==============================] - 9s 876us/step - loss: 0.6448 - acc: 0.6245 - val_loss: 0.6398 - val_acc: 0.6424\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.65091\n",
      "Epoch 39/100\n",
      "9897/9897 [==============================] - 9s 905us/step - loss: 0.6456 - acc: 0.6252 - val_loss: 0.6447 - val_acc: 0.6391\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.65091\n",
      "Epoch 40/100\n",
      "9897/9897 [==============================] - 9s 869us/step - loss: 0.6460 - acc: 0.6216 - val_loss: 0.6376 - val_acc: 0.6426\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.65091\n",
      "Epoch 41/100\n",
      "9897/9897 [==============================] - 9s 862us/step - loss: 0.6457 - acc: 0.6244 - val_loss: 0.6382 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.65091\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9897/9897 [==============================] - 7s 698us/step - loss: 0.6457 - acc: 0.6219 - val_loss: 0.6440 - val_acc: 0.6264\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.65091\n",
      "Epoch 43/100\n",
      "9897/9897 [==============================] - 7s 729us/step - loss: 0.6448 - acc: 0.6248 - val_loss: 0.6447 - val_acc: 0.6242\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.65091\n",
      "Epoch 44/100\n",
      "9897/9897 [==============================] - 7s 697us/step - loss: 0.6436 - acc: 0.6310 - val_loss: 0.6431 - val_acc: 0.6391\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.65091\n",
      "Epoch 45/100\n",
      "9897/9897 [==============================] - 8s 782us/step - loss: 0.6447 - acc: 0.6202 - val_loss: 0.6406 - val_acc: 0.6497\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.65091\n",
      "Epoch 46/100\n",
      "9897/9897 [==============================] - 7s 751us/step - loss: 0.6457 - acc: 0.6186 - val_loss: 0.6397 - val_acc: 0.6482\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.65091\n",
      "Epoch 47/100\n",
      "9897/9897 [==============================] - 8s 763us/step - loss: 0.6468 - acc: 0.6227 - val_loss: 0.6400 - val_acc: 0.6482\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.65091\n",
      "Epoch 48/100\n",
      "9897/9897 [==============================] - 8s 787us/step - loss: 0.6450 - acc: 0.6318 - val_loss: 0.6442 - val_acc: 0.6444\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.65091\n",
      "Epoch 49/100\n",
      "9897/9897 [==============================] - 8s 799us/step - loss: 0.6427 - acc: 0.6278 - val_loss: 0.6423 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.65091\n",
      "Epoch 50/100\n",
      "9897/9897 [==============================] - 8s 825us/step - loss: 0.6443 - acc: 0.6249 - val_loss: 0.6406 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.65091\n",
      "Epoch 51/100\n",
      "9897/9897 [==============================] - 8s 802us/step - loss: 0.6477 - acc: 0.6230 - val_loss: 0.6386 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.65091\n",
      "Epoch 52/100\n",
      "9897/9897 [==============================] - 8s 796us/step - loss: 0.6465 - acc: 0.6292 - val_loss: 0.6411 - val_acc: 0.6462\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.65091\n",
      "Epoch 53/100\n",
      "9897/9897 [==============================] - 8s 845us/step - loss: 0.6421 - acc: 0.6309 - val_loss: 0.6409 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.65091\n",
      "Epoch 54/100\n",
      "9897/9897 [==============================] - 8s 791us/step - loss: 0.6444 - acc: 0.6265 - val_loss: 0.6383 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.65091\n",
      "Epoch 55/100\n",
      "9897/9897 [==============================] - 4s 437us/step - loss: 0.6421 - acc: 0.6347 - val_loss: 0.6386 - val_acc: 0.6453\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.65091\n",
      "Epoch 56/100\n",
      "9897/9897 [==============================] - 1s 124us/step - loss: 0.6453 - acc: 0.6291 - val_loss: 0.6407 - val_acc: 0.6447\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.65091\n",
      "Epoch 57/100\n",
      "9897/9897 [==============================] - 2s 157us/step - loss: 0.6464 - acc: 0.6209 - val_loss: 0.6419 - val_acc: 0.6474\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.65091\n",
      "Epoch 58/100\n",
      "9897/9897 [==============================] - 1s 122us/step - loss: 0.6441 - acc: 0.6288 - val_loss: 0.6394 - val_acc: 0.6441\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.65091\n",
      "Epoch 59/100\n",
      "9897/9897 [==============================] - 1s 121us/step - loss: 0.6456 - acc: 0.6255 - val_loss: 0.6425 - val_acc: 0.6452\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.65091\n",
      "Epoch 60/100\n",
      "9897/9897 [==============================] - 1s 122us/step - loss: 0.6442 - acc: 0.6292 - val_loss: 0.6382 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.65091\n",
      "Epoch 61/100\n",
      "9897/9897 [==============================] - 1s 121us/step - loss: 0.6452 - acc: 0.6219 - val_loss: 0.6420 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.65091\n",
      "Epoch 62/100\n",
      "9897/9897 [==============================] - 1s 120us/step - loss: 0.6468 - acc: 0.6272 - val_loss: 0.6404 - val_acc: 0.6494\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.65091\n",
      "Epoch 63/100\n",
      "9897/9897 [==============================] - 1s 122us/step - loss: 0.6438 - acc: 0.6264 - val_loss: 0.6378 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.65091\n",
      "Epoch 64/100\n",
      "9897/9897 [==============================] - 1s 139us/step - loss: 0.6442 - acc: 0.6293 - val_loss: 0.6422 - val_acc: 0.6459\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.65091\n",
      "Epoch 65/100\n",
      "9897/9897 [==============================] - 1s 138us/step - loss: 0.6442 - acc: 0.6315 - val_loss: 0.6390 - val_acc: 0.6508\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.65091\n",
      "Epoch 66/100\n",
      "9897/9897 [==============================] - 1s 131us/step - loss: 0.6453 - acc: 0.6297 - val_loss: 0.6432 - val_acc: 0.6361\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.65091\n",
      "Epoch 67/100\n",
      "9897/9897 [==============================] - 1s 129us/step - loss: 0.6402 - acc: 0.6314 - val_loss: 0.6363 - val_acc: 0.6452\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.65091\n",
      "Epoch 68/100\n",
      "9897/9897 [==============================] - 1s 126us/step - loss: 0.6446 - acc: 0.6289 - val_loss: 0.6419 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.65091\n",
      "Epoch 69/100\n",
      "9897/9897 [==============================] - 1s 131us/step - loss: 0.6458 - acc: 0.6281 - val_loss: 0.6412 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.65091\n",
      "Epoch 70/100\n",
      "9897/9897 [==============================] - 1s 130us/step - loss: 0.6416 - acc: 0.6306 - val_loss: 0.6391 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.65091\n",
      "Epoch 71/100\n",
      "9897/9897 [==============================] - 1s 131us/step - loss: 0.6393 - acc: 0.6308 - val_loss: 0.6399 - val_acc: 0.6497\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.65091\n",
      "Epoch 72/100\n",
      "9897/9897 [==============================] - 1s 136us/step - loss: 0.6428 - acc: 0.6310 - val_loss: 0.6383 - val_acc: 0.6473\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.65091\n",
      "Epoch 73/100\n",
      "9897/9897 [==============================] - 1s 128us/step - loss: 0.6432 - acc: 0.6280 - val_loss: 0.6414 - val_acc: 0.6452\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.65091\n",
      "Epoch 74/100\n",
      "9897/9897 [==============================] - 1s 133us/step - loss: 0.6439 - acc: 0.6247 - val_loss: 0.6416 - val_acc: 0.6521\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.65091 to 0.65212, saving model to mpl_model.pkl\n",
      "Epoch 75/100\n",
      "9897/9897 [==============================] - 1s 129us/step - loss: 0.6449 - acc: 0.6315 - val_loss: 0.6397 - val_acc: 0.6479\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.65212\n",
      "Epoch 76/100\n",
      "9897/9897 [==============================] - 3s 283us/step - loss: 0.6432 - acc: 0.6358 - val_loss: 0.6395 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.65212 to 0.65303, saving model to mpl_model.pkl\n",
      "Epoch 77/100\n",
      "9897/9897 [==============================] - 9s 909us/step - loss: 0.6406 - acc: 0.6339 - val_loss: 0.6374 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.65303\n",
      "Epoch 78/100\n",
      "9897/9897 [==============================] - 9s 885us/step - loss: 0.6440 - acc: 0.6267 - val_loss: 0.6360 - val_acc: 0.6488\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.65303\n",
      "Epoch 79/100\n",
      "9897/9897 [==============================] - 9s 900us/step - loss: 0.6415 - acc: 0.6294 - val_loss: 0.6411 - val_acc: 0.6459\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.65303\n",
      "Epoch 80/100\n",
      "9897/9897 [==============================] - 9s 871us/step - loss: 0.6412 - acc: 0.6304 - val_loss: 0.6372 - val_acc: 0.6455\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.65303\n",
      "Epoch 81/100\n",
      "9897/9897 [==============================] - 9s 904us/step - loss: 0.6437 - acc: 0.6314 - val_loss: 0.6394 - val_acc: 0.6470\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.65303\n",
      "Epoch 82/100\n",
      "9897/9897 [==============================] - 9s 878us/step - loss: 0.6430 - acc: 0.6269 - val_loss: 0.6384 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.65303\n",
      "Epoch 83/100\n",
      "9897/9897 [==============================] - 9s 893us/step - loss: 0.6416 - acc: 0.6291 - val_loss: 0.6452 - val_acc: 0.6412\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.65303\n",
      "Epoch 84/100\n",
      "9897/9897 [==============================] - 9s 897us/step - loss: 0.6438 - acc: 0.6344 - val_loss: 0.6420 - val_acc: 0.6406\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.65303\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9897/9897 [==============================] - 7s 743us/step - loss: 0.6435 - acc: 0.6316 - val_loss: 0.6406 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.65303\n",
      "Epoch 86/100\n",
      "9897/9897 [==============================] - 7s 741us/step - loss: 0.6400 - acc: 0.6354 - val_loss: 0.6420 - val_acc: 0.6373\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.65303\n",
      "Epoch 87/100\n",
      "9897/9897 [==============================] - 8s 759us/step - loss: 0.6442 - acc: 0.6296 - val_loss: 0.6399 - val_acc: 0.6470\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.65303\n",
      "Epoch 88/100\n",
      "9897/9897 [==============================] - 7s 734us/step - loss: 0.6409 - acc: 0.6286 - val_loss: 0.6372 - val_acc: 0.6536\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.65303 to 0.65364, saving model to mpl_model.pkl\n",
      "Epoch 89/100\n",
      "9897/9897 [==============================] - 8s 804us/step - loss: 0.6432 - acc: 0.6316 - val_loss: 0.6389 - val_acc: 0.6527\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.65364\n",
      "Epoch 90/100\n",
      "9897/9897 [==============================] - 8s 828us/step - loss: 0.6439 - acc: 0.6285 - val_loss: 0.6386 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.65364\n",
      "Epoch 91/100\n",
      "9897/9897 [==============================] - 8s 824us/step - loss: 0.6454 - acc: 0.6253 - val_loss: 0.6400 - val_acc: 0.6470\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.65364\n",
      "Epoch 92/100\n",
      "9897/9897 [==============================] - 8s 817us/step - loss: 0.6449 - acc: 0.6255 - val_loss: 0.6400 - val_acc: 0.6521\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.65364\n",
      "Epoch 93/100\n",
      "9897/9897 [==============================] - 8s 814us/step - loss: 0.6404 - acc: 0.6328 - val_loss: 0.6393 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.65364\n",
      "Epoch 94/100\n",
      "9897/9897 [==============================] - 8s 811us/step - loss: 0.6412 - acc: 0.6375 - val_loss: 0.6395 - val_acc: 0.6421\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.65364\n",
      "Epoch 95/100\n",
      "9897/9897 [==============================] - 8s 820us/step - loss: 0.6399 - acc: 0.6312 - val_loss: 0.6417 - val_acc: 0.6491\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.65364\n",
      "Epoch 96/100\n",
      "9897/9897 [==============================] - 8s 812us/step - loss: 0.6432 - acc: 0.6309 - val_loss: 0.6437 - val_acc: 0.6377\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.65364\n",
      "Epoch 97/100\n",
      "9897/9897 [==============================] - 8s 820us/step - loss: 0.6383 - acc: 0.6327 - val_loss: 0.6380 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.65364\n",
      "Epoch 98/100\n",
      "9897/9897 [==============================] - 8s 853us/step - loss: 0.6458 - acc: 0.6249 - val_loss: 0.6375 - val_acc: 0.6488\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.65364\n",
      "Epoch 99/100\n",
      "9897/9897 [==============================] - 8s 821us/step - loss: 0.6425 - acc: 0.6289 - val_loss: 0.6356 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.65364\n",
      "Epoch 100/100\n",
      "9897/9897 [==============================] - 8s 833us/step - loss: 0.6406 - acc: 0.6281 - val_loss: 0.6381 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.65364\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16,activation='relu',input_shape=(4,),kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu',input_shape=(8,),kernel_initializer='normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64,activation='relu',input_shape=(8,),kernel_initializer='normal'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16,activation='relu',input_shape=(8,),kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2,activation = 'sigmoid'))\n",
    "chk = ModelCheckpoint('mpl_model.pkl', monitor='val_acc', save_best_only=True, mode='max', verbose=1)\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = Adam(),\n",
    "              metrics = ['accuracy'])\n",
    "history = model.fit(np.array(training_inputs),np.array(training_classes),\n",
    "                    batch_size = 100,\n",
    "                    epochs = 100,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[chk],\n",
    "                    validation_data = (np.array(testing_inputs),np.array(testing_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "-1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 -1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-029855914bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpredict_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtemp_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mactual_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#print(p,t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "path = 'MovementAAL/dataset/MovementAAL_RSS_'\n",
    "predict_label=[]\n",
    "actual_labels = []\n",
    "p_target = []\n",
    "#i = '200' # i = 1 to 314\n",
    "for i in range(1,315):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    #print(file_path)\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "    values = df.values\n",
    "    values = np.array(scale.fit_transform(values))\n",
    "    for j in values:\n",
    "        temp_p = []\n",
    "        p = model.predict(np.array([j])).argmax()\n",
    "        predict_label.append(p)\n",
    "        temp_p.append(p)\n",
    "        t = targets[int(i)]\n",
    "        actual_labels.append(t)\n",
    "        #print(p,t)\n",
    "    if temp_p.count(1) < temp_p.count(0):\n",
    "        p_target.append(-1)\n",
    "    else:\n",
    "        p_target.append(1)\n",
    "    print(targets[i-1],p_target[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313,)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(p_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
